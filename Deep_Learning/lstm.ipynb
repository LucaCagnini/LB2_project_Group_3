{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1304fd5-0ee5-4d6a-aa42-85bd22909a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b05af4-e6a3-49ca-8154-84d4030ff0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_one_hot_sets(dataset):\n",
    "    sets = [\"1\",\"2\",\"3\",\"4\",\"5\",\"Benchmark\"]\n",
    "    set_results=[]\n",
    "    for i in sets:\n",
    "        st=dataset.query(f\"Set == '{i}'\")\n",
    "        tmp_x=[]\n",
    "        tmp_y=[]\n",
    "        for _ , row in st.iterrows():\n",
    "            seq=row[\"Sequence\"]\n",
    "            if len(seq) < 90:\n",
    "                seq=_increase_lenseq(seq)\n",
    "            else:\n",
    "                seq=seq[:90]\n",
    "            encoded_seq = one_hot_encoding(seq)\n",
    "            tmp_x.append(encoded_seq)\n",
    "            \n",
    "            if row[\"Class\"] == \"Positive\":\n",
    "                y=1\n",
    "            else:\n",
    "                y=0\n",
    "            tmp_y.append(y)\n",
    "\n",
    "        tmp_x=np.array(tmp_x, dtype=np.float32)\n",
    "        tmp_y=np.array(tmp_y, dtype=np.float32)\n",
    "        set_results.append((tmp_x , tmp_y))\n",
    "    return set_results\n",
    "            \n",
    "def _increase_lenseq(seq):\n",
    "    x=len(seq)\n",
    "    num_of_X= 90-x\n",
    "    seq=seq+(\"X\"*num_of_X)\n",
    "    return seq\n",
    "            \n",
    "def one_hot_encoding(sequence):\n",
    "    M = []\n",
    "    aa_alph = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y','X']\n",
    "    for aa in sequence:\n",
    "        one_hot = np.zeros(21)\n",
    "        try:\n",
    "            index = aa_alph.index(aa)\n",
    "            one_hot[index] = 1\n",
    "        except:\n",
    "            pass\n",
    "        M.append(one_hot)\n",
    "    M = np.array(M)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c9a309-27b6-46ff-a909-6007ed6041a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SP_NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes,lstm_hidden_size, num_lstm_layers, output_size, dropout_p=0.5):\n",
    "        super(SP_NN, self).__init__()\n",
    "# 1. LSTM (Parte fissa che estrae le features temporali)\n",
    "        # input_size = 21 (One-Hot)\n",
    "        self.cnn_out_channels = 64\n",
    "        self.conv1 = nn.Conv1d(input_size, self.cnn_out_channels, kernel_size=17, padding='same')\n",
    "        self.lstm = nn.LSTM(self.cnn_out_channels, lstm_hidden_size, num_lstm_layers, \n",
    "                            batch_first=True, dropout=dropout_p if num_lstm_layers > 1 else 0)\n",
    "        \n",
    "        # 2. Batch Norm (Stabilizza l'output dell'LSTM)\n",
    "        self.bn = nn.BatchNorm1d(lstm_hidden_size)\n",
    "        \n",
    "        # 3. COSTRUZIONE DINAMICA DELL'MLP (La parte che hai chiesto)\n",
    "        mlp_layers = []\n",
    "        \n",
    "        # ATTENZIONE: L'input dell'MLP è l'output dell'LSTM!\n",
    "        current_input_size = lstm_hidden_size \n",
    "        \n",
    "        # Ciclo dinamico preso dal tuo vecchio codice\n",
    "        for hidden_size in hidden_sizes:\n",
    "            # Layer Lineare\n",
    "            mlp_layers.append(nn.Linear(current_input_size, hidden_size))\n",
    "            # Attivazione\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            # Dropout\n",
    "            mlp_layers.append(nn.Dropout(p=dropout_p))\n",
    "            # Aggiorna dimensione\n",
    "            current_input_size = hidden_size\n",
    "            \n",
    "        # Layer finale di output (riduzione a 1)\n",
    "        mlp_layers.append(nn.Linear(current_input_size, output_size))\n",
    "        \n",
    "        # Sigmoide finale (Se usi BCELoss. Se usi BCEWithLogitsLoss, toglilo!)\n",
    "        mlp_layers.append(nn.Sigmoid()) \n",
    "        \n",
    "        # Impacchetta tutto nel Sequential\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1) \n",
    "        x = self.conv1(x)       # Esce [Batch, 64, 90]\n",
    "        \n",
    "        # --- PASSAGGIO LSTM ---\n",
    "        # L'LSTM vuole [Batch, Lunghezza, Canali] -> permutiamo indietro\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :] # Prendi solo l'output finale (il \"riassunto\" dopo aver letto tutta la sequenza durante l'lstm) in pratica trasforma il vettore Batch,90,Hidden in Batch,Hidden. In sintesi fa si che l'output sia definito al 90-esimo timestamp, ovvero quando lstm ha letto tutti e 90 gli aminaocidi e ha formulato l'ipotesi con la conoscenza dei 90 precedenti aminaoccidi.\n",
    "        out = self.bn(out)\n",
    "\n",
    "        # Decode the hidden state of each time step\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "# Define a custom dataset\n",
    "class SignalDataset(Dataset): #prepara i dati convertendoli in tensori\n",
    "    def __init__(self, X, y):\n",
    "        # Tieni i dati come sono (Numpy o Liste). NON convertirli subito.\n",
    "        # Questo non occupa memoria extra.\n",
    "        self.X = X \n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Converti in Tensore SOLO quando il dato viene richiesto\n",
    "        #    Questo risparmia tantissima RAM.\n",
    "        x_out = torch.from_numpy(self.X[idx]).float() \n",
    "        \n",
    "        # 2. Gestione Etichetta (Label)\n",
    "        #    .view(1) o .unsqueeze(0) serve per trasformare lo scalare \"0\" in un vettore \"[0]\"\n",
    "        #    Questo evita errori con la BCELoss che si aspetta dimensioni compatibili.\n",
    "        y_out = torch.tensor(self.y[idx], dtype=torch.float32).view(1)\n",
    "        \n",
    "        return x_out, y_out\n",
    "\n",
    "\n",
    "def train_val(model, #è il modello da addestrare\n",
    "              train_loader, #i dati da studiare, diviso in batch\n",
    "              val_loader, #il test da fare a fine  di ogni studio\n",
    "              optimizer, #metodo di studio (adam, RMSprop ecc.. dice al modlelo come aggiornare le sue consocenze).\n",
    "              criterion, #il correttore, che dice al modello di quanto ha sbagliato\n",
    "              epochs, #quante volte il modello rileggerà i dati per impararne\n",
    "              patience, #quante volte il modello può fare un esame di prova peggiore del precedente prima di interrompere le epoche in anticipo\n",
    "              scorer = matthews_corrcoef,\n",
    "              init_best_score = -1,\n",
    "              output_transform = lambda x: (x > 0.5).float()): #come tradurre la probabilità del modello, praticamente trasforma i valori in 1 e 0\n",
    "  best_val_score = init_best_score #inizializza il miglior punteggio\n",
    "  epochs_without_improvement = 0 #contatore della patience utile per vedere quante volte di fila non migliora\n",
    "  best_model_state_dict = None #prepara il cassetto dove inserirci il modello che ha performato meglio\n",
    "\n",
    "  for epoch in range(epochs): #ripeti il processo per epoche volte. \n",
    "      # Training\n",
    "      model.train()  #inizializzi il modello vuoto da allenare\n",
    "      loss = 0 #inizializzi la variabile per la loss\n",
    "      for batch_X, batch_y in train_loader: #questo for itera su tutti i batches\n",
    "          batch_X, batch_y = batch_X.to(device), batch_y.to(device) #sposta eventualmente i dati del batch sulla gpu se disponibile per fare i calcoli piu velocemente\n",
    "          optimizer.zero_grad() #azzera l'optimizer che era stato utilizzato per il batch precedente\n",
    "          outputs = model(batch_X) #il modello legge il batch x e produce le risposte\n",
    "          loss = criterion(outputs, batch_y) # il correttore calcola il singolo numero di errore confrontando le risposte date dal modello con quelle del batch y\n",
    "          loss.backward() #funzione di pytorch che  si guarda quanto ogni peso ha contribuito a quell'errore  tramite il calcolo del gradiente quindi dice di quanto un peso deve scendere o salire.\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "          optimizer.step() #prende i calcoli della backward e aggiorna fisicamente i pesi del cervello per ridurre l'errore\n",
    "\n",
    "      # Validation\n",
    "      model.eval() #è cruciale perche mette il modello in fase di valutazione, spegnendo il dropout, ovvero quello che spegneva neuroni a caso per evitare overfitting\n",
    "      val_preds = []\n",
    "      val_labels = []\n",
    "      with torch.no_grad(): #dice a pytorch di non calcolare gradienti, poiche siamo in fase di valutazione, rendendo il tutto piu veloce e consumando meno memoria\n",
    "          for batch_X, batch_y in val_loader: #itera su tutti i batch del validation\n",
    "              batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "              outputs = model(batch_X)\n",
    "              #preds = (outputs > 0.5).float() #qui invece utilizzi direttamente questo modo per trasformare gli output in 0 e 1\n",
    "              preds = output_transform(outputs) #utilizza il metodo di traformazione conenuto in output _transform permettendolo di variare a piacimento\n",
    "              val_preds.extend(preds.cpu().numpy().flatten()) #aggiunge le risposte alle liste\n",
    "              val_labels.extend(batch_y.cpu().numpy().flatten())\n",
    "      val_score = scorer(val_labels, val_preds) #calcola il punteggio MCC alla fine di ogni test\n",
    "\n",
    "      if val_score > best_val_score:\n",
    "          best_val_score = val_score\n",
    "          epochs_without_improvement = 0\n",
    "          best_model_state_dict = model.state_dict()\n",
    "          print('Validation score improved to {:.4f}'.format(best_val_score))\n",
    "      else:\n",
    "          epochs_without_improvement += 1\n",
    "          if epochs_without_improvement >= patience:\n",
    "              print('Early stopping at epoch {}'.format(epoch+1))\n",
    "              break\n",
    "\n",
    "      print('Epoch [{}/{}], Loss: {:.4f}, Val score: {:.4f}'.format(epoch+1, epochs, loss.item(), val_score))\n",
    "  return best_model_state_dict\n",
    "\n",
    "def test(model, test_loader, scorer = matthews_corrcoef, output_transform = lambda x: (x > 0.5).float()):\n",
    "  model.eval()\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with torch.no_grad():\n",
    "      for batch_X, batch_y in test_loader:\n",
    "          batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "          outputs = model(batch_X)\n",
    "          preds = output_transform(outputs)\n",
    "          all_preds.extend(preds.cpu().numpy().flatten())\n",
    "          all_labels.extend(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "  score = scorer(all_labels, all_preds)\n",
    "  return score\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6304579e-a9dc-4b3b-924b-46bb0ca7db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carica tutto il CSV\n",
    "dataset = pd.read_csv(\"../Data_Preparation/train_bench.tsv\", sep=\"\\t\")\n",
    "\n",
    "# 2. Elabora tutto in una volta (La lista conterrà 6 elementi ordinati)\n",
    "all_data = create_one_hot_sets(dataset)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7914c37d-f167-4926-b933-8d03b74bb021",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9867f98f-efa2-4702-95d0-a7dc0d694493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6200e1-b495-41e4-9e27-3cd080b66e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hidden_layer_size(config):\n",
    "    pool = [1024, 512, 256, 128, 64, 32] #pool di dimensioni disponibili. modifica qui se vuoi cambiare le dimensioni possibili di ogni layer\n",
    "    num_layers = config[\"num_layers\"] \n",
    "    #imposta che se il numero di layer viene settato dall'utente maggiore dei pool, lo imposti come lunghezza massima il numero di pool (per evitare che due layer abbiano le stesse dimensioni)\n",
    "    if num_layers > len(pool):\n",
    "        num_layers = len(pool)\n",
    "    chosen_dims = random.sample(pool, num_layers) \n",
    "    #permette di scegliere randomicamente se usare la struttura a imbuto (grande, piccolo, grande) o in ordine decrescente(come il prof, dal piu grande al piu piccolo)\n",
    "    if random.choice([True, False]): # 50% di possibilità di essere True\n",
    "        # SÌ, FUNNEL method (Stabile): Ordina dalla più grande alla più piccola\n",
    "        final_dims = sorted(chosen_dims, reverse=True)\n",
    "        # Questo testerà l'ipotesi di stabilità\n",
    "    else:\n",
    "        # NO, CLESSIDRA/FLESSIBILE: Mescola l'ordine\n",
    "        random.shuffle(chosen_dims)\n",
    "        final_dims = chosen_dims\n",
    "    return final_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473ee00e-7e34-4aae-ab3c-d9ac13bc9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_layers\": tune.choice([2,3,4,5]),\n",
    "    \"hidden_sizes\": tune.sample_from(generate_hidden_layer_size),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-3),\n",
    "    \"batch_size\": tune.choice([10, 20]),\n",
    "    \"num_lstm_layers\": tune.choice([1, 2]),\n",
    "    \"lstm_hidden_size\": tune.choice([64, 128])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b059cb-e737-4bb7-aaa9-8b4739609866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_config(config):\n",
    "    mcc_scores = []\n",
    "    for i in range(5):\n",
    "        training_indices = [(i+1)%5, (i+2)%5, (i+3)%5]\n",
    "        validation_index = (i+4)%5\n",
    "        testing_index = i\n",
    "        # 2. PREPARAZIONE TRAINING (Concatenare 3 set)\n",
    "        # Raccogliamo le X dei 3 set di training\n",
    "        train_x_list = [all_data[j][0] for j in training_indices]\n",
    "        # Raccogliamo le y dei 3 set di training\n",
    "        train_y_list = [all_data[j][1] for j in training_indices]\n",
    "        \n",
    "        # Uniamo tutto in un unico array gigante\n",
    "        x_train_conc = np.concatenate(train_x_list, axis=0)\n",
    "        y_train_conc = np.concatenate(train_y_list, axis=0)\n",
    "        \n",
    "        # 3. PREPARAZIONE VALIDATION & TEST (Singoli set)\n",
    "        x_val = all_data[validation_index][0]\n",
    "        y_val = all_data[validation_index][1]\n",
    "        \n",
    "        x_test = all_data[testing_index][0]\n",
    "        y_test = all_data[testing_index][1]\n",
    "\n",
    "        # 4. CREAZIONE DATASET (Usa la tua classe SignalDataset lazy)\n",
    "        # Nota: Non serve trasformare in tensori qui, lo fa il Dataset dentro __getitem__\n",
    "        train_dataset = SignalDataset(x_train_conc, y_train_conc)\n",
    "        val_dataset = SignalDataset(x_val, y_val)\n",
    "        test_dataset = SignalDataset(x_test, y_test)\n",
    "\n",
    "        # 5. DATALOADERS\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"])\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"])\n",
    "        # --- MODELLO ---\n",
    "        model = SP_NN(\n",
    "            input_size=21, \n",
    "            hidden_sizes=config[\"hidden_sizes\"],\n",
    "            lstm_hidden_size=config[\"lstm_hidden_size\"],\n",
    "            num_lstm_layers=config[\"num_lstm_layers\"],\n",
    "            output_size=1,\n",
    "            dropout_p=config[\"dropout\"]\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        # Training (Verbose False per pulizia)\n",
    "        best_state = train_val(model, train_loader, val_loader, optimizer, criterion,\n",
    "                               epochs=100, patience=20)\n",
    "        \n",
    "        model.load_state_dict(best_state)\n",
    "        \n",
    "        mcc = test(model, test_loader)\n",
    "        mcc_scores.append(mcc)\n",
    "        mean_mcc = np.mean(mcc_scores)\n",
    "    \n",
    "    # Formattiamo la stringa per la tabella\n",
    "    arch_str = str(config[\"hidden_sizes\"])\n",
    "    \n",
    "    tune.report({\"mcc\": mean_mcc, \"loss\": -mean_mcc, \"hidden_layers_size\": arch_str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3181c84-d095-4557-9aed-72c52891868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 10:27:03,818\tINFO worker.py:2012 -- Started a local Ray instance.\n",
      "/home/markus/anaconda3/envs/lab1/lib/python3.13/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "2025-11-19 10:27:05,861\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2025-11-19 10:27:05,864\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-19 10:27:09,384\tINFO tensorboardx.py:193 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2025-11-19 10:27:09,447\tWARNING callback.py:143 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-19 10:28:27</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:18.29        </td></tr>\n",
       "<tr><td>Memory:      </td><td>2.6/3.5 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/4 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  lstm_hidden_size</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  num_lstm_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>test_config_ec0fe_00000</td><td>RUNNING </td><td>172.19.13.131:1508</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\"> 0.110972</td><td style=\"text-align: right;\">0.000974084</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">                2</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (72 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2025-11-19 10:27:30,807 E 1168 1168] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[33m(raylet)\u001b[0m [2025-11-19 10:27:32,888 E 1245 1245] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2025-11-19 10:27:35,929 E 1144 1326] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(bundle_reservation_check_func pid=1327)\u001b[0m [2025-11-19 10:27:35,878 E 1327 1402] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(test_config pid=1508)\u001b[0m Validation score improved to 0.0000\n",
      "\u001b[36m(test_config pid=1508)\u001b[0m Epoch [1/100], Loss: 0.1459, Val score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(test_config pid=1508)\u001b[0m [2025-11-19 10:27:45,311 E 1508 1534] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(test_config pid=1508)\u001b[0m Epoch [2/100], Loss: 0.3553, Val score: 0.0000\n",
      "\u001b[36m(test_config pid=1508)\u001b[0m Epoch [3/100], Loss: 0.9576, Val score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "result = tune.run(\n",
    "    test_config,\n",
    "    config=config,\n",
    "    num_samples=15,\n",
    "    max_concurrent_trials=1 # OBBLIGATORIO PER NON CRASHARE LA RAM\n",
    ")\n",
    "\n",
    "best_trial = result.get_best_trial(\"mcc\", \"max\", \"last\")\n",
    "print(\"Best trial config:\", best_trial.config)\n",
    "print(\"Best CV MCC:\", best_trial.last_result[\"mcc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
