{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ebd48d8-e619-4f3f-aad1-b40011f797bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceacb35-f07d-4792-8067-777f5ce8bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal SVM training for feature selection\n",
    "\n",
    "# We'll use a simple StandardScaler + RBF SVM pipeline\n",
    "def svm_pipeline(C, gamma):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", SVC(kernel=\"rbf\", C=C, gamma=gamma, random_state=42))\n",
    "    ])\n",
    "\n",
    "#------------\n",
    "\n",
    "#nel nostro caso possiamo fare una roba del genere (fuori dal ciclo for dove iteriamo su gamma e c)\n",
    "pipeline = Pipeline([(\"scaler\" , StandardScaler()) , (\"svm\" , SVC())])\n",
    "# e poi all'interno di ogni iterazione\n",
    "pipeline.set_params(svm__kernel=\"rbf\",svm__C=C , svm__gamma=gamma) #per settare i parametri della svm, volendo si può iterare anche sul kernel\n",
    "#con set params possiamo anche cambiare i parametri dello standard scaler\n",
    "pipeline.fit(X_train, y_train) #addestra lo scaler e l'svm in base ai dati. Nel caso dello scaler non è che impara qualcosa veramente come nel caso \n",
    "#dell'svm o di modelli predittivi in generale. \n",
    "#Ma bensi memorizza calcola e memorizza mean e stdv, da usare poi scaler.transform(X) per trasformare questi dati. \n",
    "score = pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098fbe3-c99e-41cb-96c7-0a99bb0b57a3",
   "metadata": {},
   "source": [
    "la funzione pipeline serve semplicemente per stabilire un ordine di cose da fare (nel caso sopra scale e creare la svm)\n",
    "cosi che puoi successivamente riciclare la tua funzione pipeline ad esempio per usarla in diversi dataset.\n",
    "viene usata per la cross validation. Non è necessario definire una funzione come fa il prof. Si può direttamente usare pipeline\n",
    "IMPORTANTE: pipeline.score returna l'accuracy. Questo per noi non va bene visto che abbiamo classi sbilanciate.\n",
    "quello che possiamo fare allora è il seguente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208cb5a-9d2d-4bf0-916a-523326b7da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "y_pred = pipeline.predict(X_test) #che cos'è sta roba??? a noi non serve in teoria abbiamo gia y_pred o no?? -CUS\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "# e usare l'mcc come score invece che l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b8607b-c6c4-437d-b031-a8b8aee6ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop per la grid search\n",
    "C_grid = [0.1, 1.0, 10.0, 100.0]\n",
    "gamma_grid = [\"scale\", 0.01, 0.1, 1.0]\n",
    "\n",
    "best_score_base = -np.inf\n",
    "best_params_base = None\n",
    "\n",
    "for C in C_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        pipe = svm_pipeline(C, gamma)\n",
    "        pipe.fit(X_train, y_train)                 # fit on TRAIN\n",
    "        val_acc = pipe.score(X_val, y_val)         # evaluate on VALIDATION\n",
    "        if val_acc > best_score_base:\n",
    "            best_score_base = val_acc\n",
    "            best_params_base = {\"C\": C, \"gamma\": gamma}\n",
    "\n",
    "print(\"Baseline SVM (all features) — best validation accuracy: \"\n",
    "      f\"{best_score_base:.3f} with params {best_params_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38a094-0566-408a-974c-dacefb537a04",
   "metadata": {},
   "source": [
    "in questo step c'è semplicemente la grid search per trovare il miglior C e gamma. Possiamo modificare il codice come ho scritto sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca927d-b3eb-4e36-a9de-311773bd3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop per la grid search modificato\n",
    "pipeline = Pipeline([(\"scaler\" , StandardScaler()) , (\"svm\" , SVC())])\n",
    "\n",
    "C_grid = [0.1, 1.0, 10.0, 100.0]\n",
    "gamma_grid = [\"scale\", 0.01, 0.1, 1.0]\n",
    "\n",
    "best_mcc = -1\n",
    "best_params_base = None\n",
    "\n",
    "for C in C_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        pipeline.set_params(svm__kernel=\"rbf\",svm__C=C , svm__gamma=gamma)\n",
    "        pipe.fit(X_train, y_train)                 # fit on TRAIN\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)      \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_params_base = {\"C\": C, \"gamma\": gamma}\n",
    "\n",
    "print(\"Baseline SVM (all features) — best validation accuracy: \"\n",
    "      f\"{best_score_base:.3f} with params {best_params_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab119d-a8d2-42c6-a468-95b743f05751",
   "metadata": {},
   "source": [
    "fin adesso semplcemente abbiamo settato dei parametri ottimale per un svm base che possiamo usare in seguito per testare le features selezionate dalla random forest. Quindi adesso dobbiamo fare la random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4472c97-28e0-4ee5-89d2-b0683505e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    n_jobs=-1\n",
    ") \n",
    "#costruttore della random forest. n_jobs si riferisce al numero di operazioni .fit da parallelizzare (visto che gli alberi sono indipendenti)\n",
    "# -1 vuol dire utilizzare tutti i processori in parallelo. \n",
    "\n",
    "rf.fit(X_train, y_train)  # fit only on TRAIN\n",
    "\n",
    "gini_imp = pd.Series(rf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "# la funzione feature_importances_ calcola l'importanza delle features basandosi sull impurità\n",
    "\n",
    "# da qui in poi è semplicemente plotting e cazzate varie. \n",
    "gini_df = gini_imp.reset_index()\n",
    "gini_df.columns = [\"feature\", \"importance\"]\n",
    "print(\"Top 10 features by Gini importance:\")\n",
    "print(gini_df.head(10))\n",
    "\n",
    "# Plot top 20\n",
    "plt.figure()\n",
    "plt.barh(gini_df[\"feature\"].head(20)[::-1], gini_df[\"importance\"].head(20)[::-1])\n",
    "plt.xlabel(\"Gini importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"RandomForest Gini Importances (Top 20)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354a317-f983-412d-9aab-393b989e3480",
   "metadata": {},
   "source": [
    "IMPORTANTE \" impurity-based feature importance for trees is strongly biased and favor high cardinality features (typically numerical features) over low cardinality features such as binary features or categorical variables with a small number of possible categories.\n",
    "\n",
    "Permutation-based feature importances do not exhibit such a bias.\"\n",
    "questo ce scritto sul sito di scikit-learn. Permutation-based feature importances sono un altro modo per calcolare l'importanza delle features usando RandomForest ma senza basarsi sull impurità. Se nel nostro dataset ci sono sia feature prettamente numeriche e feature categoriche, allora ci conviene usare il secondo metodo, altrimenti anche quello del prof va bene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ab78f-e269-4c82-b150-6ed26eed6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_on_subset(C, gamma, subset_features):\n",
    "    # subset by feature names\n",
    "    idx = [np.where(feature_names == f)[0][0] for f in subset_features]\n",
    "    # questa sintassi terribile seleziona solo le feature in subset_features\n",
    "    # np.where resistuisce le posizioni dove feature_names è uguale a f (che sono le fatures in subset features\n",
    "    # feature names è un array (ma anche una lista va bene) che contiene i nomi delle features, cosi da poterne tenere traccia.\n",
    "    Xtr = X_train[:, idx]\n",
    "    Xva = X_val[:, idx]\n",
    "    # con sta roba prendiamo solo le colonne che ci interessano\n",
    "    pipe = svm_pipeline(C, gamma)\n",
    "    pipe.fit(Xtr, y_train)     # train on TRAIN only\n",
    "    y_pred = pipeline.predict(x_test) # predict on test data\n",
    "            mcc = matthews_corrcoef(y_test, y_pred) # compute MCC \n",
    "    return pipe.score(Xva, y_val)  # accuracy on VALIDATION\n",
    "\n",
    "#possiamo modificare le ultime righe di questo codice se utilizzano la pipeline come ho detto io. Possiamo anche \n",
    "#qui usare un altra metric invece dell accuracy \n",
    "\n",
    "\n",
    "\n",
    "# We'll sweep k and, for each k, re-evaluate the best baseline SVM params on the reduced feature set\n",
    "ks = list(range(2, min(26, X_train.shape[1]+1)))  # keep it small for speed/clarity\n",
    "curve = []\n",
    "\n",
    "for k in ks:\n",
    "    subset = gini_df[\"feature\"].head(k).tolist()\n",
    "    acc_k = accuracy_on_subset(best_params_base[\"C\"], best_params_base[\"gamma\"], subset)\n",
    "    curve.append(acc_k)\n",
    "\n",
    "#gini_df contiene una classifica di feature ordinate per importanza Gini (probabilmente da una Random Forest).\n",
    "#Per ogni k (da 2 a max 25 o numero di feature disponibili):\n",
    "#Prende le prime k feature più importanti (head(k)).\n",
    "#Calcola l’accuracy sul validation set usando solo quelle feature.\n",
    "#Salva il risultato in curve.\n",
    "# questo l ha fatto chat pk mi sono rotto il cazzo, comunque in questo script prende quindi , \n",
    "# prima la feature piu importante, poi la prima e la seconda, poi prima seconda e terza, finche non le usa tutte.\n",
    "#ogni volta calcola l accuracy dopo aver provato la SVM base di prima. \n",
    "\n",
    "best_k_idx = int(np.argmax(curve))\n",
    "#argmax ti returna l indice del valore piu alto in quella lista.\n",
    "best_k = ks[best_k_idx]\n",
    "print(f\"Best k on validation (using baseline best params): k={best_k}, val_acc={curve[best_k_idx]:.3f}\")\n",
    "\n",
    "#trova k che massimizza la curva, poi solo plotting \n",
    "plt.figure()\n",
    "plt.plot(ks, curve, marker=\"o\")\n",
    "plt.xlabel(\"k (top features by RF Gini)\")\n",
    "plt.ylabel(\"Validation accuracy (SVM)\")\n",
    "plt.title(\"Accuracy vs. Number of Selected Features (Validation set)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502b6c2-f6af-43ed-9360-4b58adf0ce5e",
   "metadata": {},
   "source": [
    "PARTE FINALE: ALLENARE L'SVM FINALE\n",
    "\n",
    "Dobbiamo fare due cose: di nuovo una grid search per scegliere i parametri migliori.\n",
    "E dobbiamo scegliere quali e quante feauture usare.\n",
    "dobbiamo guardare tutti i parametri che ci ha dato la cross validation\n",
    "possiamo mettere in una lista tutti i valori migliori di k e testarli uno ad uno sul testing set e poi scegliere il migliore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b405058-d45e-4208-abdf-7000638874cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best k from the validation curve\n",
    "# --> nel nostro caso abbiamo piu k e dobbiamo iterare\n",
    "best_subset = gini_df[\"feature\"].head(best_k).tolist()\n",
    "idx = [np.where(feature_names == f)[0][0] for f in best_subset]\n",
    "\n",
    "Xtr_sel = X_train[:, idx]\n",
    "Xva_sel = X_val[:, idx]\n",
    "Xte_sel = X_test[:, idx]\n",
    "# in questa parte vengono tagliate le colonne del dataset per comprendere solo le k features.\n",
    "\n",
    "# Manual grid search again but now restricted to the selected features\n",
    "best_score_sel = -np.inf\n",
    "best_params_sel = None\n",
    "\n",
    "for C in C_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        pipe = svm_pipeline(C, gamma)\n",
    "        pipe.fit(Xtr_sel, y_train)      # train on TRAIN\n",
    "        val_acc = pipe.score(Xva_sel, y_val)  # validate on VAL\n",
    "        if val_acc > best_score_sel:\n",
    "            best_score_sel = val_acc\n",
    "            best_params_sel = {\"C\": C, \"gamma\": gamma}\n",
    "# visto che questo è il modello finale, direi di scegliere una grid piu ampia, scegliendo come base i valori \n",
    "# di c e gamma ottenuti nelle varie run di cross validation\n",
    "\n",
    "#TRAINING FINALE DEL SVM\n",
    "\n",
    "# Train final model on TRAIN+VAL with best params (optional) or just TRAIN; here we keep TRAIN only as per your outline\n",
    "final_pipe = svm_pipeline(best_params_sel[\"C\"], best_params_sel[\"gamma\"])\n",
    "final_pipe.fit(Xtr_sel, y_train)\n",
    "test_acc = final_pipe.score(Xte_sel, y_test)\n",
    "\n",
    "print(\"Selected features (best k):\", best_subset)\n",
    "print(\"Best validation accuracy on selected features:\", f\"{best_score_sel:.3f}\", \"with\", best_params_sel)\n",
    "print(\"Test accuracy (selected features, tuned on val):\", f\"{test_acc:.3f}\")\n",
    "\n",
    "# For comparison: test accuracy with all features using baseline best params\n",
    "baseline_pipe = svm_pipeline(best_params_base[\"C\"], best_params_base[\"gamma\"])\n",
    "baseline_pipe.fit(X_train, y_train)\n",
    "test_acc_all = baseline_pipe.score(X_test, y_test)\n",
    "print(\"Test accuracy (all features, baseline tuned on val):\", f\"{test_acc_all:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
