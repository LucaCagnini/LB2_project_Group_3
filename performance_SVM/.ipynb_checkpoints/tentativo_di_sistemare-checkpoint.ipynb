{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c3d422-3fbb-4b7d-a9b2-556ef492c315",
   "metadata": {},
   "source": [
    "# CUSTOM FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16f71a64-6cd0-47e5-a101-16d3d230bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import import_ipynb\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis, ProtParamData\n",
    "import statistics as st\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af4b55a1-1b86-4372-b89f-8ed9b5a0ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pswm(training,upstream_position,downstream_position):\n",
    "    \"\"\"\n",
    "    Build a Position Specific Weight Matrix (PSWM) from protein sequences.\n",
    "    \"\"\"\n",
    "    training.reset_index(inplace=True)  # Reset index for convenience and ensure compatibility with the function\n",
    "    # Extract the subsequence around the cleavage site for each protein\n",
    "    training=training.query(\"Class=='Positive'\")\n",
    "    \n",
    "    for index,row in training.iterrows():\n",
    "        sequence_to_recover=row[\"Sequence\"]\n",
    "        cleavage_position=int(row[\"SPEnd\"])\n",
    "        training.loc[index, \"Sequence\"] = sequence_to_recover[cleavage_position-upstream_position:cleavage_position+downstream_position]\n",
    "  \n",
    "    # Initialize PSWM dictionary with one entry per amino acid\n",
    "    pswm = {\"A\": \"\", \"R\": \"\", \"N\": \"\", \"D\": \"\", \"C\": \"\", \"Q\": \"\", \"E\": \"\", \"G\": \"\", \"H\": \"\", \"I\": \"\", \"L\": \"\", \"K\": \"\", \"M\": \"\", \"F\": \"\", \"P\": \"\", \"S\": \"\", \"T\": \"\", \"W\": \"\", \"Y\": \"\", \"V\": \"\"}\n",
    "    position=[]\n",
    "\n",
    "    # Background frequencies from SwissProt\n",
    "    swiss_frequencies = { \"A\" : 0.0825 , \"R\" : 0.0552 , \"N\" : 0.0406 , \"D\" : 0.0546 , \"C\" : 0.0138 , \"Q\" : 0.0393, \"E\" : 0.0671, \"G\" : 0.0707, \"H\" : 0.0227, \"I\" : 0.0590 ,\"L\" : 0.0964, \"K\" : 0.0579, \"M\" : 0.0241, \"F\" : 0.0386, \"P\" : 0.0474, \"S\" : 0.0665, \"T\" : 0.0536, \"W\" : 0.0110, \"Y\" : 0.0292 , \"V\": 0.0685}\n",
    "   \n",
    "    # Initialize counts with 1 (pseudocounts)\n",
    "    for i in range(len(training.loc[1,\"Sequence\"])):\n",
    "        position.append(1)\n",
    "    for key in pswm:\n",
    "        pswm[key]=position[:]\n",
    "        \n",
    "    #update all the counts for each position and aminoacid\n",
    "    i=0\n",
    "    for index, row in training.iterrows():\n",
    "        i=0\n",
    "        for aa in row[\"Sequence\"]:\n",
    "            if aa=='X':\n",
    "                pass\n",
    "            else:\n",
    "                pswm[aa][i]+=1\n",
    "            i+=1\n",
    "    \n",
    "    N=len(training) #number of sequences\n",
    "    \n",
    "    # Compute log-odds scores for the PSWM\n",
    "    for key in pswm:\n",
    "        for i in range(len(pswm[key])):\n",
    "            pswm[key][i]=math.log((pswm[key][i]/(N+20))/swiss_frequencies[key])\n",
    "    return pswm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad5b2605-63f8-461b-8c5d-8486de653ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count efficiently aminoacids frequencies\n",
    "def selected_residue_composition(sequence):\n",
    "    # define aminoacids order\n",
    "    aa_order = \"CDMNR\"\n",
    "    counts_vector=[]\n",
    "    length=len(sequence)\n",
    "    for aa in aa_order:\n",
    "        counts_vector.append(sequence.count(aa)/length)\n",
    "    return counts_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efd6fa84-f461-4f19-91a6-84b50b7628a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that computes the VonHeijne matrix\n",
    "def vonheijne_feature(matrix , seq): \n",
    "    \n",
    "    # Iterate among all sequences of the set \n",
    "    \n",
    "    validation_scores = []      # List that only contains the scores\n",
    "    pos = 0                 # Counter for window size tracking\n",
    "    aa = 0                  # Index that moves along the sequence\n",
    "    tmp_score = 0           # Initialize window score\n",
    "    max_window_score = -math.inf \n",
    "        \n",
    "    end = min(90, len(seq)) # We end iterating on the sequence when we reach the 90th aa or when the \n",
    "                                # sequence ends (sequence length < 90 aa)\n",
    "        \n",
    "    while aa < end - 14:    # Iteration on the sequence\n",
    "        while pos <= 14:    # Iteration while the window is less than the fixed window size\n",
    "            \n",
    "            try:            # Try statement to handle aminoacids not found in the matrix\n",
    "                tmp_score += matrix[seq[aa + pos]][pos] # computing the score of the window\n",
    "                \n",
    "            except KeyError :\n",
    "                tmp_score += 0\n",
    "            pos +=1         # Increasing the window size counter\n",
    "            \n",
    "        if tmp_score > max_window_score: # Checking if the actual window has a better score than the previous one\n",
    "            max_window_score = tmp_score\n",
    "        \n",
    "        aa += 1             # Increase the starting point\n",
    "        pos = 0             # Reset the window size\n",
    "        tmp_score = 0       # Reset window score\n",
    "\n",
    "            \n",
    "    return max_window_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e54ceb6-8a4a-4a50-b249-9a680c966491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_features (seq, scale ,window): \n",
    "        \n",
    "    ''' This function returns the features (max score and average score) of a chosen scale for a specific sequence. You can use a personalized \n",
    "    dictionary of scores or a one inside ProtParamData. You can check all the ProtParamData scales using the command dir(ProtParamData) A legend of each \n",
    "    param argument is given at the beginning of this file'''\n",
    "\n",
    "    sequence = ProteinAnalysis(seq) \n",
    "    if type(scale)==dict:   \n",
    "        scale_result = sequence.protein_scale(scale, window, edge=1)\n",
    "        if len(seq)<window:\n",
    "            scale_result = sequence.protein_scale(scale, len(seq), edge=1)\n",
    "    else:\n",
    "        param_dict = getattr(ProtParamData, scale)\n",
    "        scale_result = sequence.protein_scale(param_dict, window, edge=1)\n",
    "        if len(seq)<window:\n",
    "            scale_result = sequence.protein_scale(param_dict, len(seq), edge=1)\n",
    "    max_value=max(scale_result)\n",
    "    mean_value=st.mean(scale_result)\n",
    "    return max_value , mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bbca3e0-de91-43e3-8ff5-db21c939a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features to use from the feature selection:\n",
    "#features_to_use=['VhonHeijne', 'C', 'tm_tendency_max', 'chou_fasman_h_mean', 'max_miyazawa_mean', 'D', 'T', 'R', 'chou_fasma_b_max', 'N', 'flexibility_max', 'punta_max', 'bulkiness_mean', 'M', 'argos_max']\n",
    "def get_selected_features(set_n, matrix, window):\n",
    "    all_features_result=[]\n",
    "    #bulkiness dictionary for prot param function\n",
    "    bulkiness = { \"A\": 11.500  , \"R\": 14.280  , \"N\": 12.820  ,\"D\": 11.680  ,\"C\": 13.460  ,\"Q\": 14.450  ,\"E\": 13.570  ,\"G\":  3.400  , \"H\": 13.690  , \"I\": 21.400  , \"L\": 21.400  , \"K\": 15.710  , \"M\": 16.250  , \"F\": 19.800  , \"P\": 17.430  , \"S\":  9.470  , \"T\": 15.770  , \"W\": 21.670  , \"Y\": 18.030  ,  \"V\": 21.570 }\n",
    "    #transmembrane tendency dictionary for prot param function recovered from https://web.expasy.org/protscale/pscale/Transmembranetendency.html\n",
    "    tm_tendency_custom =     {'A':  0.380,     'R': -2.570,    'N': -1.620,     'D': -3.270,    'C': -0.300,     'Q': -1.840,     'E': -2.900,    'G': -0.190,    'H': -1.440,     'I':  1.970,     'L':  1.820,     'K': -3.460,     'M':  1.400,     'F':  1.980,    'P': -1.440,    'S': -0.530,     'T': -0.320,     'W':  1.530,     'Y':  0.490,    'V':  1.400  }\n",
    "    argos = getattr(ProtParamData, \"ag\")\n",
    "    #Miyazawa hydrophobicity inverse\n",
    "    miyazawa = getattr(ProtParamData, \"mi\")\n",
    "    #Flexibility scale\n",
    "    flexibility = getattr(ProtParamData, \"Flex\")\n",
    "    #Knowledge-based membrane-propensity scale from 1D_Helix in MPtopo databases (Punta-Maritan, 2003)\n",
    "    punta = {\"A\": -0.17, \"L\": -0.28, \"R\": 0.37, \"K\": 0.32, \"N\": 0.18, \"M\": -0.26, \"D\": 0.37, \"F\": -0.41, \"C\": -0.06, \"P\": 0.13, \"Q\": 0.26, \"S\": 0.05, \"E\": 0.15, \"T\": 0.02, \"G\": 0.01, \"W\": -0.15, \"H\": -0.02, \"Y\": -0.09, \"I\": -0.28, \"V\": -0.17}\n",
    "    #Normalized frequency of alpha-helix (Chou-Fasman, 1978b)\n",
    "    chou_fasman_h = {\"A\": 1.42, \"L\": 1.21, \"R\": 0.98, \"K\": 1.16, \"N\": 0.67, \"M\": 1.45, \"D\": 1.01, \"F\": 1.13, \"C\": 0.70, \"P\": 0.57, \"Q\": 1.11, \"S\": 0.77, \"E\": 1.51, \"T\": 0.83, \"G\": 0.57, \"W\": 1.08, \"H\": 1.00, \"Y\": 0.69, \"I\": 1.08, \"V\": 1.06}\n",
    "    #Normalized frequency of beta-sheets (Chou-Fasman, 1978b)\n",
    "    chou_fasman_b = {\"A\": 0.83, \"L\": 1.30, \"R\": 0.93, \"K\": 0.74, \"N\": 0.89, \"M\": 1.05, \"D\": 0.54, \"F\": 1.38, \"C\": 1.19, \"P\": 0.55, \"Q\": 1.10, \"S\": 0.75, \"E\": 0.37, \"T\": 1.19, \"G\": 0.75, \"W\": 1.37, \"H\": 0.87, \"Y\": 1.47, \"I\": 1.60, \"V\": 1.70}\n",
    "    \n",
    "    features_to_use=[(tm_tendency_custom , \"max\"), (chou_fasman_h , \"mean\"), (miyazawa , \"mean\"), (chou_fasman_b, \"max\"), (flexibility , \"max\"), (punta , \"max\"), (bulkiness , \"mean\"), (argos , \"max\") ]\n",
    "\n",
    "    #extract each sequence in the set\n",
    "    for seq in set_n:\n",
    "        seq=seq.replace(\"X\" , \"\")\n",
    "        seq=seq.replace(\"U\" , \"C\")\n",
    "        seq_features = [] \n",
    "        #extract each feature type for each sequence\n",
    "        for scale in features_to_use: #extract the max_value and avg_value of scale features\n",
    "            max_value,avg_value = get_scale_features(seq, scale[0], window)\n",
    "            if scale[1]==\"max\":\n",
    "                seq_features.append(max_value)\n",
    "            else:\n",
    "                seq_features.append(avg_value)\n",
    "        vonhejine=vonheijne_feature(matrix, seq) #get the von heijne feature for that sequence\n",
    "        composition=selected_residue_composition(seq) #get the selected aminaocid composition frequency\n",
    "        #append all the features of that specific sequence\n",
    "        seq_features.append(vonhejine)\n",
    "        seq_features=seq_features+composition\n",
    "        #add these feature to the total feature list\n",
    "        all_features_result.append(seq_features) # aggiungo la riga al risultato finale\n",
    "    X = np.array(all_features_result) #transform the list that contains all the features in an array\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0b1ca4e-4cf1-487f-9739-b268058a914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features to use from the feature selection:\n",
    "features_to_use=['VhonHeijne', 'C', 'tm_tendency_max', 'chou_fasman_h_mean', 'max_miyazawa_mean', 'D', 'T', 'R', 'chou_fasma_b_max', 'N', 'flexibility_max', 'punta_max', 'bulkiness_mean', 'M', 'argos_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6307ae62-1afb-4f2d-8fd3-f64cc11526b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# compute the feature set:\n",
    "dataset=pd.read_csv(\"../Data_Preparation/train_bench.tsv\", sep='\\t')\n",
    "training=dataset.query(\"Set != 'Benchmark'\")\n",
    "benchmark=dataset.query(\"Set == 'Benchmark'\")\n",
    "\n",
    "mat=get_pswm(training ,13 ,2 )\n",
    "train_matrix=get_selected_features(training[\"Sequence\"] , mat , 15)\n",
    "\n",
    "#training vector:\n",
    "tr_vector_neg_pos = training[\"Class\"]\n",
    "tr_vector_proper = tr_vector_neg_pos.map({\"Positive\": 1, \"Negative\": 0})\n",
    "tr_target_vector = tr_vector_proper.to_numpy()\n",
    "#benchmark:\n",
    "bn_vector_neg_pos = benchmark[\"Class\"]\n",
    "bn_vector_proper = bn_vector_neg_pos.map({\"Positive\": 1, \"Negative\": 0})\n",
    "bn_target_vector = bn_vector_proper.to_numpy()\n",
    "\n",
    "print(tr_target_vector)\n",
    "print(bn_target_vector)\n",
    "\n",
    "x_benchmark=get_selected_features(benchmark[\"Sequence\"] , mat , 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c1813-96f5-42a4-a68f-94e907d2e14f",
   "metadata": {},
   "source": [
    "# SVM TESTING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a88da3b-25f4-42b3-9e0e-6e4542a390b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "#! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef , confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44c45624-a121-43b8-a8f3-f4deb82cbfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set: 0.8119764250066371\n"
     ]
    }
   ],
   "source": [
    "#create the pipeline\n",
    "pipeline = Pipeline([(\"scaler\" , StandardScaler()) , (\"svm\" , SVC(cache_size=1500))])\n",
    "#predict the benchmark set\n",
    "classifier=pipeline.set_params(svm__C=2.687775805186727, svm__gamma=0.012249546394282136, svm__kernel='rbf').fit(train_matrix , tr_target_testing_vector) \n",
    "bench_pred = pipeline.predict(x_benchmark)\n",
    "#compute the mcc\n",
    "mcc = matthews_corrcoef(bn_target_vector , bench_pred)\n",
    "print(f\"MCC on testing set: {mcc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
